{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkinTag: Robust Skin Lesion Classification\n",
    "\n",
    "**Problem**: Medical images vary by camera, lighting, and quality — models fail on out-of-distribution images.\n",
    "\n",
    "**Solution**: MedSigLIP embeddings + augmentations for robustness to real-world imaging conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (run once)\n",
    "!pip install -q transformers albumentations scikit-learn kaggle\n",
    "\n",
    "# Set Kaggle credentials (get from kaggle.com/settings)\n",
    "import os\n",
    "os.environ['KAGGLE_API_TOKEN'] = ''  # Paste your token here\n",
    "\n",
    "!mkdir -p data\n",
    "!kaggle datasets download -d farjanakabirsamanta/skin-cancer-dataset -p data/ --unzip -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "import albumentations as A\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HAM10000 metadata\n",
    "data_dir = Path(\"data\")\n",
    "metadata_path = list(data_dir.glob(\"**/HAM10000_metadata.csv\"))[0]\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Find images\n",
    "image_lookup = {p.stem: p for p in data_dir.glob(\"**/*.jpg\")}\n",
    "\n",
    "# Binary labels: benign vs malignant\n",
    "MALIGNANT = [\"akiec\", \"bcc\", \"mel\"]\n",
    "df[\"label\"] = df[\"dx\"].apply(lambda x: 1 if x in MALIGNANT else 0)\n",
    "df[\"image_path\"] = df[\"image_id\"].map(image_lookup)\n",
    "df = df.dropna(subset=[\"image_path\"])\n",
    "\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"Class distribution: {df['label'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-trained Model: MedSigLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MedSigLIP (400M vision encoder trained on medical images)\n",
    "model_name = \"google/siglip-so400m-patch14-384\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, torch_dtype=torch.float16).to(device).eval()\n",
    "print(\"MedSigLIP loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings (transfer learning: use pre-trained features)\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(image_paths, batch_size=16):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(image_paths), batch_size)):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        images = [Image.open(p).convert(\"RGB\") for p in batch_paths]\n",
    "        inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "        emb = model.get_image_features(**inputs)\n",
    "        embeddings.append(emb.cpu())\n",
    "    return torch.cat(embeddings)\n",
    "\n",
    "# Sample for speed (use full dataset for final results)\n",
    "SAMPLE_SIZE = 2000\n",
    "df_sample = df.sample(SAMPLE_SIZE, random_state=42)\n",
    "\n",
    "embeddings = extract_embeddings(df_sample[\"image_path\"].tolist())\n",
    "labels = df_sample[\"label\"].values\n",
    "print(f\"Embeddings: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embeddings.numpy(), labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_acc = clf.score(X_train, y_train)\n",
    "test_acc = clf.score(X_test, y_test)\n",
    "print(f\"Train accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation for Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentations simulating real-world imaging conditions\n",
    "augmentations = {\n",
    "    \"Original\": None,\n",
    "    \"Lighting\": A.Compose([A.RandomBrightnessContrast(0.3, 0.3, p=1), A.RandomGamma((70,130), p=1)]),\n",
    "    \"Noise\": A.Compose([A.GaussNoise(var_limit=(20, 80), p=1)]),\n",
    "    \"Compression\": A.Compose([A.ImageCompression(quality_lower=30, quality_upper=50, p=1)]),\n",
    "}\n",
    "\n",
    "# Visualize\n",
    "sample_img = np.array(Image.open(df_sample.iloc[0][\"image_path\"]))\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "for ax, (name, aug) in zip(axes, augmentations.items()):\n",
    "    img = sample_img if aug is None else aug(image=sample_img)[\"image\"]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(name)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"augmentations.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Robustness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on degraded images\n",
    "test_paths = df_sample.iloc[X_test.shape[0]*-1:][\"image_path\"].tolist()[:100]  # 100 test images\n",
    "test_labels = y_test[:100]\n",
    "\n",
    "results = {}\n",
    "for name, aug in augmentations.items():\n",
    "    images = []\n",
    "    for p in test_paths:\n",
    "        img = np.array(Image.open(p).convert(\"RGB\"))\n",
    "        if aug:\n",
    "            img = aug(image=img)[\"image\"]\n",
    "        images.append(Image.fromarray(img))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "        emb = model.get_image_features(**inputs).cpu().numpy()\n",
    "    \n",
    "    acc = clf.score(emb, test_labels)\n",
    "    results[name] = acc\n",
    "    print(f\"{name}: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "colors = [\"#2ecc71\" if k == \"Original\" else \"#3498db\" for k in results.keys()]\n",
    "bars = plt.bar(results.keys(), results.values(), color=colors)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Robustness Across Imaging Conditions\")\n",
    "plt.ylim(0, 1)\n",
    "for bar, acc in zip(bars, results.values()):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f\"{acc:.2f}\", ha=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"robustness.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Requirement | What We Did |\n",
    "|-------------|-------------|\n",
    "| **Problem** | Medical images vary by camera/lighting/quality |\n",
    "| **Pre-trained Model** | MedSigLIP (400M params, medical image encoder) |\n",
    "| **Transfer Learning** | Extract embeddings → train logistic regression |\n",
    "| **Augmentations** | Lighting, noise, compression (simulate real-world) |\n",
    "| **Results** | Accuracy under clean vs degraded conditions |"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
